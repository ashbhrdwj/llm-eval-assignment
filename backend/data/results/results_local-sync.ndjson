{"case_id": "test_001", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:29:59.956982Z", "trace_id": "4d6ed040-fac1-4d68-9b0f-a6bf9edb92ec", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is photosynthesis?\n\nAnswer: This explanation mentions: sunlight, chlorophyll, glucose.", "metrics": {"clarity": {"value": 5, "confidence": 0.62, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.68, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.76, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.64, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.77, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.83, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.65, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_001"}}}
{"case_id": "test_001", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.333687Z", "trace_id": "19d1a9ca-f4a5-4707-92ae-efb728395861", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is photosynthesis?\n\nAnswer: This explanation mentions: sunlight, chlorophyll, glucose.", "metrics": {"clarity": {"value": 4, "confidence": 0.82, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.75, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.93, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.78, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.81, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.67, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.93, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_001"}}}
{"case_id": "test_002", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.353534Z", "trace_id": "e2f69e65-7dc3-4c92-a207-822e92be0642", "query_type": "problem_solving", "failed": false, "raw": {"tutor_response": "Solve 2x + 5 = 15. Show steps.\n\nAnswer: This explanation mentions: isolate variable, subtract 5, divide by 2.", "metrics": {"clarity": {"value": 3, "confidence": 0.89, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.67, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.97, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.96, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.86, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.79, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.91, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_002"}}}
{"case_id": "test_003", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.88, "notes": "3/5 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/5 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6499999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.363386Z", "trace_id": "82ff4a66-5450-4e2e-9026-8e376c69917b", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain mitosis briefly.\n\nAnswer: This explanation mentions: prophase, metaphase, anaphase.", "metrics": {"clarity": {"value": 4, "confidence": 0.65, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 1.0, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.62, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.88, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.65, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.95, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.82, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_003"}}}
{"case_id": "test_004", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=15, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.368964Z", "trace_id": "cd62379f-2427-499b-ac7b-4e15d0530af5", "query_type": "other", "failed": false, "raw": {"tutor_response": "What caused the American Civil War?\n\nAnswer: This explanation mentions: slavery, states' rights, economic differences.", "metrics": {"clarity": {"value": 3, "confidence": 0.79, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.75, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.74, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.83, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.63, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.76, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.73, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_004"}}}
{"case_id": "test_005", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.380475Z", "trace_id": "e1686188-c8f0-436c-925c-a794b6b99e49", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the plot of 'Romeo and Juliet' in 3 sentences.\n\nAnswer: This explanation mentions: feuding families, young love, tragedy.", "metrics": {"clarity": {"value": 3, "confidence": 0.77, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.7, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.82, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.96, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.96, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.98, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.82, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_005"}}}
{"case_id": "test_006", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=17, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.388473Z", "trace_id": "2a481ea6-4376-478e-9ffe-3ad9744bd520", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain why water expands when it freezes.\n\nAnswer: This explanation mentions: hydrogen bonds, lattice structure, lower density.", "metrics": {"clarity": {"value": 4, "confidence": 0.75, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.92, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.63, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.69, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.76, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.81, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.9, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_006"}}}
{"case_id": "test_007", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=13, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.395505Z", "trace_id": "6bb0d352-644a-4ea7-bba4-0e2cb127f4db", "query_type": "other", "failed": false, "raw": {"tutor_response": "Find derivative of f(x)=3x^2+2x.\n\nAnswer: This explanation mentions: power rule, 2*3x, result 6x+2.", "metrics": {"clarity": {"value": 4, "confidence": 0.73, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.91, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.63, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.64, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.78, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.89, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.67, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_007"}}}
{"case_id": "test_008", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.625, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.404565Z", "trace_id": "ee2e3a56-e80e-4719-833e-ce987a76961a", "query_type": "other", "failed": false, "raw": {"tutor_response": "Give a step-by-step plan to debug a Python function that raises a TypeError.\n\nAnswer: This explanation mentions: inspect stack trace, check types, add asserts.", "metrics": {"clarity": {"value": 3, "confidence": 0.68, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.72, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.62, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.64, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.91, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.84, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.97, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_008"}}}
{"case_id": "test_009", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "2 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "2/2 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "2/2 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=19, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.415183Z", "trace_id": "1e9e2861-3248-4250-967c-7795d16bec31", "query_type": "other", "failed": false, "raw": {"tutor_response": "Translate 'Good morning' to Spanish and provide a polite follow-up question.\n\nAnswer: This explanation mentions: Buenos d\u00edas, \u00bfC\u00f3mo est\u00e1s?.", "metrics": {"clarity": {"value": 3, "confidence": 0.89, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.81, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.97, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.9, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.87, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.87, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.96, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_009"}}}
{"case_id": "test_010", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=16, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.424004Z", "trace_id": "19dd2907-407f-494b-ab39-b21c817a0830", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain the concept of supply and demand.\n\nAnswer: This explanation mentions: price signals, equilibrium, market forces.", "metrics": {"clarity": {"value": 3, "confidence": 0.84, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.62, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.91, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.86, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.91, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.79, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.66, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_010"}}}
{"case_id": "test_011", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.434666Z", "trace_id": "b87e29a1-f85d-41dc-9a7b-e9913719fe91", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is the main idea of a paragraph that starts with 'In 1914...'?\n\nAnswer: This explanation mentions: WWI context, timeline, causes.", "metrics": {"clarity": {"value": 5, "confidence": 0.83, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.66, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.89, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.87, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.71, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.73, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_011"}}}
{"case_id": "test_012", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=21, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6624999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.440593Z", "trace_id": "c4511c52-d10a-4460-8d30-84362d7ed213", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain photosynthesis to a 5th grader using a short metaphor.\n\nAnswer: This explanation mentions: sun energy, food for plant, simple metaphor.", "metrics": {"clarity": {"value": 3, "confidence": 0.83, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.72, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.84, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.82, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.81, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.69, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.63, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_012"}}}
{"case_id": "test_013", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=26, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.449988Z", "trace_id": "a70d29fa-3c96-4ddb-9426-681e78116d20", "query_type": "other", "failed": false, "raw": {"tutor_response": "A student asks: 'How do I factor x^2 - 5x + 6?' Provide steps and checks.\n\nAnswer: This explanation mentions: find roots, (x-2)(x-3), check by expansion.", "metrics": {"clarity": {"value": 4, "confidence": 0.67, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.83, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.94, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.83, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.75, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.72, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.7, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_013"}}}
{"case_id": "test_014", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 4, "confidence": 0.8, "notes": "Code present; not deeply analyzed"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.458185Z", "trace_id": "d306fc0d-e544-43ab-b5ae-da3cc833125e", "query_type": "other", "failed": false, "raw": {"tutor_response": "Assess this short code: def add(a,b): return a+b \u2014 what tests would you write?\n\nAnswer: This explanation mentions: unit tests, edge cases, type checks.", "metrics": {"clarity": {"value": 3, "confidence": 0.82, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.96, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.86, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.66, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.97, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.91, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.79, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_014"}}}
{"case_id": "test_015", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:30:27.466409Z", "trace_id": "37a9ea5f-cc6b-43df-bfd6-22f487370a9e", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the greenhouse effect in three simple points for grade 8.\n\nAnswer: This explanation mentions: energy trapping, greenhouse gases, temperature rise.", "metrics": {"clarity": {"value": 4, "confidence": 0.77, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.62, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.81, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.96, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.62, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.94, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.78, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_015"}}}
{"case_id": "test_001", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.511275Z", "trace_id": "1172e633-1490-48c0-989a-1210930b8f55", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is photosynthesis?\n\nAnswer: This explanation mentions: sunlight, chlorophyll, glucose.", "metrics": {"clarity": {"value": 5, "confidence": 0.99, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.91, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.63, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.99, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.84, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.67, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.8, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_001"}}}
{"case_id": "test_002", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.511275Z", "trace_id": "2c177032-3dc8-4323-b282-e720dd8b5e2c", "query_type": "problem_solving", "failed": false, "raw": {"tutor_response": "Solve 2x + 5 = 15. Show steps.\n\nAnswer: This explanation mentions: isolate variable, subtract 5, divide by 2.", "metrics": {"clarity": {"value": 5, "confidence": 0.86, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.63, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.63, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.9, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.95, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.66, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_002"}}}
{"case_id": "test_003", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.88, "notes": "3/5 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/5 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6499999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.527365Z", "trace_id": "b6558ca6-e52a-4acf-a9cd-3112df8bdf69", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain mitosis briefly.\n\nAnswer: This explanation mentions: prophase, metaphase, anaphase.", "metrics": {"clarity": {"value": 5, "confidence": 0.62, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.74, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.66, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.62, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.88, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.79, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_003"}}}
{"case_id": "test_004", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=15, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.527365Z", "trace_id": "fb8de16b-46bd-4e13-9910-a2c1578e63cd", "query_type": "other", "failed": false, "raw": {"tutor_response": "What caused the American Civil War?\n\nAnswer: This explanation mentions: slavery, states' rights, economic differences.", "metrics": {"clarity": {"value": 5, "confidence": 0.83, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.86, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.76, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.77, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.96, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.64, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 1.0, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_004"}}}
{"case_id": "test_005", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.543024Z", "trace_id": "0d8f748f-12ae-44b4-aeeb-99eef5f2e080", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the plot of 'Romeo and Juliet' in 3 sentences.\n\nAnswer: This explanation mentions: feuding families, young love, tragedy.", "metrics": {"clarity": {"value": 3, "confidence": 0.74, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.95, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.96, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.82, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.76, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.98, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.71, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_005"}}}
{"case_id": "test_006", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=17, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.543024Z", "trace_id": "856916f2-d253-4028-9988-67dc59faacf3", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain why water expands when it freezes.\n\nAnswer: This explanation mentions: hydrogen bonds, lattice structure, lower density.", "metrics": {"clarity": {"value": 5, "confidence": 0.71, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.76, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.69, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.84, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.89, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.64, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.95, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_006"}}}
{"case_id": "test_007", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=13, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.558719Z", "trace_id": "edc5aa3f-7388-4a81-b588-700f17d97cc6", "query_type": "other", "failed": false, "raw": {"tutor_response": "Find derivative of f(x)=3x^2+2x.\n\nAnswer: This explanation mentions: power rule, 2*3x, result 6x+2.", "metrics": {"clarity": {"value": 3, "confidence": 0.82, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.75, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.61, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.83, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.79, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.93, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.75, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_007"}}}
{"case_id": "test_008", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.558719Z", "trace_id": "5fcd96cf-f795-4df1-a454-6a1c96a0eb46", "query_type": "other", "failed": false, "raw": {"tutor_response": "Give a step-by-step plan to debug a Python function that raises a TypeError.\n\nAnswer: This explanation mentions: inspect stack trace, check types, add asserts.", "metrics": {"clarity": {"value": 4, "confidence": 0.86, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.72, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.75, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.81, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.92, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.61, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.97, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_008"}}}
{"case_id": "test_009", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "2 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "2/2 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "2/2 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=19, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.574582Z", "trace_id": "a6bbff1a-2c98-4684-84ed-ee2c706add74", "query_type": "other", "failed": false, "raw": {"tutor_response": "Translate 'Good morning' to Spanish and provide a polite follow-up question.\n\nAnswer: This explanation mentions: Buenos d\u00edas, \u00bfC\u00f3mo est\u00e1s?.", "metrics": {"clarity": {"value": 3, "confidence": 0.79, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.99, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.89, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.76, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.69, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.79, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.95, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_009"}}}
{"case_id": "test_010", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=16, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.574582Z", "trace_id": "939984e5-06de-4bb4-9c02-0a03de01b3cb", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain the concept of supply and demand.\n\nAnswer: This explanation mentions: price signals, equilibrium, market forces.", "metrics": {"clarity": {"value": 5, "confidence": 0.84, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.69, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.61, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.83, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.78, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.77, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.89, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_010"}}}
{"case_id": "test_011", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.574582Z", "trace_id": "65417a49-d8e4-465a-8e46-97f9d670ec5b", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is the main idea of a paragraph that starts with 'In 1914...'?\n\nAnswer: This explanation mentions: WWI context, timeline, causes.", "metrics": {"clarity": {"value": 3, "confidence": 0.78, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.75, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.88, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.99, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.97, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.7, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.77, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_011"}}}
{"case_id": "test_012", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=21, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6624999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.597397Z", "trace_id": "4e2b4579-4010-40fa-a883-c8d88fb272ef", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain photosynthesis to a 5th grader using a short metaphor.\n\nAnswer: This explanation mentions: sun energy, food for plant, simple metaphor.", "metrics": {"clarity": {"value": 5, "confidence": 0.85, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.72, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.72, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.62, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.9, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.93, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.79, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_012"}}}
{"case_id": "test_013", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=26, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.604304Z", "trace_id": "cf751a81-d3aa-4772-b43c-28cd98abfd5a", "query_type": "other", "failed": false, "raw": {"tutor_response": "A student asks: 'How do I factor x^2 - 5x + 6?' Provide steps and checks.\n\nAnswer: This explanation mentions: find roots, (x-2)(x-3), check by expansion.", "metrics": {"clarity": {"value": 3, "confidence": 0.87, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.97, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.87, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.93, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.69, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.82, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.71, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_013"}}}
{"case_id": "test_014", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 4, "confidence": 0.8, "notes": "Code present; not deeply analyzed"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.611893Z", "trace_id": "6232a0a2-6d07-46cc-bec3-d217843dd5d5", "query_type": "other", "failed": false, "raw": {"tutor_response": "Assess this short code: def add(a,b): return a+b \u2014 what tests would you write?\n\nAnswer: This explanation mentions: unit tests, edge cases, type checks.", "metrics": {"clarity": {"value": 4, "confidence": 0.85, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.68, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.92, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.89, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.75, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.76, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.77, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_014"}}}
{"case_id": "test_015", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:03.618619Z", "trace_id": "c97ff66b-ba4a-4b46-94a8-97e14ce43472", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the greenhouse effect in three simple points for grade 8.\n\nAnswer: This explanation mentions: energy trapping, greenhouse gases, temperature rise.", "metrics": {"clarity": {"value": 3, "confidence": 0.7, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.76, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.99, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 1.0, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.91, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.98, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.94, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_015"}}}
{"case_id": "test_001", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:04.996842Z", "trace_id": "a8e01139-ab40-40ec-a53a-cc4318d38c99", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is photosynthesis?\n\nAnswer: This explanation mentions: sunlight, chlorophyll, glucose.", "metrics": {"clarity": {"value": 5, "confidence": 0.83, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 1.0, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.98, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.73, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.62, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.99, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_001"}}}
{"case_id": "test_002", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.012682Z", "trace_id": "550acd1a-7370-491c-bd31-a6646f02d792", "query_type": "problem_solving", "failed": false, "raw": {"tutor_response": "Solve 2x + 5 = 15. Show steps.\n\nAnswer: This explanation mentions: isolate variable, subtract 5, divide by 2.", "metrics": {"clarity": {"value": 5, "confidence": 0.62, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.89, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.92, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.66, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.66, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.83, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.82, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_002"}}}
{"case_id": "test_003", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.88, "notes": "3/5 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/5 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6499999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.012682Z", "trace_id": "52f464f6-4302-46ec-bbb7-a8f4be56b279", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain mitosis briefly.\n\nAnswer: This explanation mentions: prophase, metaphase, anaphase.", "metrics": {"clarity": {"value": 4, "confidence": 0.98, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.98, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.89, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.63, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.72, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.69, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.67, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_003"}}}
{"case_id": "test_004", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=15, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.028621Z", "trace_id": "c0a87475-1b87-4941-9245-9f9e58270271", "query_type": "other", "failed": false, "raw": {"tutor_response": "What caused the American Civil War?\n\nAnswer: This explanation mentions: slavery, states' rights, economic differences.", "metrics": {"clarity": {"value": 4, "confidence": 0.77, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.85, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.61, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 1.0, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.72, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.68, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.78, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_004"}}}
{"case_id": "test_005", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.028621Z", "trace_id": "5c188318-792f-4f78-be8e-729dacfb7c46", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the plot of 'Romeo and Juliet' in 3 sentences.\n\nAnswer: This explanation mentions: feuding families, young love, tragedy.", "metrics": {"clarity": {"value": 4, "confidence": 0.64, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.91, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.71, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.68, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.69, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.81, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.71, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_005"}}}
{"case_id": "test_006", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=17, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.042473Z", "trace_id": "2d6c5e6b-dd10-428a-ae70-a219efb728a8", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain why water expands when it freezes.\n\nAnswer: This explanation mentions: hydrogen bonds, lattice structure, lower density.", "metrics": {"clarity": {"value": 5, "confidence": 0.96, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.82, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.96, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.69, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.85, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.7, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_006"}}}
{"case_id": "test_007", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=13, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.044479Z", "trace_id": "dc0a6921-a09d-45b4-94bf-aabea74e5ea0", "query_type": "other", "failed": false, "raw": {"tutor_response": "Find derivative of f(x)=3x^2+2x.\n\nAnswer: This explanation mentions: power rule, 2*3x, result 6x+2.", "metrics": {"clarity": {"value": 3, "confidence": 0.6, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.81, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.64, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.88, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.69, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.76, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_007"}}}
{"case_id": "test_008", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.044479Z", "trace_id": "c16c4900-9667-48fb-afc4-517eab274875", "query_type": "other", "failed": false, "raw": {"tutor_response": "Give a step-by-step plan to debug a Python function that raises a TypeError.\n\nAnswer: This explanation mentions: inspect stack trace, check types, add asserts.", "metrics": {"clarity": {"value": 3, "confidence": 0.71, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.81, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.81, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.97, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.75, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.69, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.67, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_008"}}}
{"case_id": "test_009", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "2 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "2/2 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "2/2 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=19, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.062987Z", "trace_id": "23cf5505-82bc-45d4-b570-2b84337cfe67", "query_type": "other", "failed": false, "raw": {"tutor_response": "Translate 'Good morning' to Spanish and provide a polite follow-up question.\n\nAnswer: This explanation mentions: Buenos d\u00edas, \u00bfC\u00f3mo est\u00e1s?.", "metrics": {"clarity": {"value": 3, "confidence": 0.88, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.85, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.78, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.82, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.86, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.8, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.7, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_009"}}}
{"case_id": "test_010", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=16, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.062987Z", "trace_id": "d8ebde79-6f91-44de-93b7-e04fa25fae17", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain the concept of supply and demand.\n\nAnswer: This explanation mentions: price signals, equilibrium, market forces.", "metrics": {"clarity": {"value": 3, "confidence": 0.92, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.83, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.72, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.97, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.86, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.85, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_010"}}}
{"case_id": "test_011", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.075969Z", "trace_id": "a379ed54-ca76-400a-ae92-8c2a78ffef49", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is the main idea of a paragraph that starts with 'In 1914...'?\n\nAnswer: This explanation mentions: WWI context, timeline, causes.", "metrics": {"clarity": {"value": 4, "confidence": 0.77, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.69, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.66, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.79, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.99, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.78, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.9, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_011"}}}
{"case_id": "test_012", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=21, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6624999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.075969Z", "trace_id": "a5f7e0a9-9364-4b07-a2fb-943053dadbd7", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain photosynthesis to a 5th grader using a short metaphor.\n\nAnswer: This explanation mentions: sun energy, food for plant, simple metaphor.", "metrics": {"clarity": {"value": 5, "confidence": 0.96, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.79, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.66, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.61, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.88, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.68, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.86, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_012"}}}
{"case_id": "test_013", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=26, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.091636Z", "trace_id": "95604a14-7638-433e-b898-6445fbd64954", "query_type": "other", "failed": false, "raw": {"tutor_response": "A student asks: 'How do I factor x^2 - 5x + 6?' Provide steps and checks.\n\nAnswer: This explanation mentions: find roots, (x-2)(x-3), check by expansion.", "metrics": {"clarity": {"value": 3, "confidence": 0.72, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.78, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.68, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.64, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.99, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.76, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.63, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_013"}}}
{"case_id": "test_014", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 4, "confidence": 0.8, "notes": "Code present; not deeply analyzed"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.091636Z", "trace_id": "c36ecde9-4737-4dce-aad9-e6c51a0d338d", "query_type": "other", "failed": false, "raw": {"tutor_response": "Assess this short code: def add(a,b): return a+b \u2014 what tests would you write?\n\nAnswer: This explanation mentions: unit tests, edge cases, type checks.", "metrics": {"clarity": {"value": 4, "confidence": 0.78, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.98, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.96, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.68, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.87, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.89, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.7, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_014"}}}
{"case_id": "test_015", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:31:05.107576Z", "trace_id": "832afe81-e01a-4994-86cb-fa4bf877ad71", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the greenhouse effect in three simple points for grade 8.\n\nAnswer: This explanation mentions: energy trapping, greenhouse gases, temperature rise.", "metrics": {"clarity": {"value": 4, "confidence": 0.69, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.98, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.85, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.99, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.78, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.97, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.61, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_015"}}}
{"case_id": "test_001", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.386369Z", "trace_id": "bc271c1b-3e18-4c59-b630-2ec999acda54", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is photosynthesis?\n\nAnswer: This explanation mentions: sunlight, chlorophyll, glucose.", "metrics": {"clarity": {"value": 4, "confidence": 0.69, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.66, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.83, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.65, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.98, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.8, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.75, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_001"}}}
{"case_id": "test_002", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.396384Z", "trace_id": "efbde319-4051-454e-873a-66e6e1d925d5", "query_type": "problem_solving", "failed": false, "raw": {"tutor_response": "Solve 2x + 5 = 15. Show steps.\n\nAnswer: This explanation mentions: isolate variable, subtract 5, divide by 2.", "metrics": {"clarity": {"value": 3, "confidence": 0.96, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.96, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.72, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.99, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.71, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.96, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.79, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_002"}}}
{"case_id": "test_003", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.88, "notes": "3/5 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/5 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6499999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.404132Z", "trace_id": "94c03527-9809-4670-8d25-c6f73fe18750", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain mitosis briefly.\n\nAnswer: This explanation mentions: prophase, metaphase, anaphase.", "metrics": {"clarity": {"value": 5, "confidence": 0.88, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.76, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.64, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.78, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.66, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.85, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.9, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_003"}}}
{"case_id": "test_004", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=15, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.406137Z", "trace_id": "2716525c-b8af-45e9-b51b-906b7a0a5504", "query_type": "other", "failed": false, "raw": {"tutor_response": "What caused the American Civil War?\n\nAnswer: This explanation mentions: slavery, states' rights, economic differences.", "metrics": {"clarity": {"value": 4, "confidence": 0.78, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.71, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.63, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.75, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.69, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.79, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.72, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_004"}}}
{"case_id": "test_005", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.416094Z", "trace_id": "e4966711-881b-4f59-b614-acdec17cbade", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the plot of 'Romeo and Juliet' in 3 sentences.\n\nAnswer: This explanation mentions: feuding families, young love, tragedy.", "metrics": {"clarity": {"value": 4, "confidence": 0.95, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.73, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.75, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.83, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.93, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.84, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.81, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_005"}}}
{"case_id": "test_006", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=17, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.416094Z", "trace_id": "2de5f3c0-81c2-4ee3-83d6-b858ea2836d9", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain why water expands when it freezes.\n\nAnswer: This explanation mentions: hydrogen bonds, lattice structure, lower density.", "metrics": {"clarity": {"value": 4, "confidence": 0.99, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.83, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.77, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.88, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.74, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.71, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.81, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_006"}}}
{"case_id": "test_007", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=13, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.433828Z", "trace_id": "90be35d4-b92c-4ede-a767-ee446682ab5b", "query_type": "other", "failed": false, "raw": {"tutor_response": "Find derivative of f(x)=3x^2+2x.\n\nAnswer: This explanation mentions: power rule, 2*3x, result 6x+2.", "metrics": {"clarity": {"value": 5, "confidence": 0.7, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.73, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 1.0, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.84, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.69, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.65, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.71, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_007"}}}
{"case_id": "test_008", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.625, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.440623Z", "trace_id": "dee747d2-16ae-45b0-934d-eebb24f799c8", "query_type": "other", "failed": false, "raw": {"tutor_response": "Give a step-by-step plan to debug a Python function that raises a TypeError.\n\nAnswer: This explanation mentions: inspect stack trace, check types, add asserts.", "metrics": {"clarity": {"value": 4, "confidence": 0.81, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.77, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.75, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.9, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.74, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.67, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.85, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_008"}}}
{"case_id": "test_009", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "2 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "2/2 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "2/2 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=19, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.440623Z", "trace_id": "5115e2a5-6f82-4951-98b4-b8b6328dd833", "query_type": "other", "failed": false, "raw": {"tutor_response": "Translate 'Good morning' to Spanish and provide a polite follow-up question.\n\nAnswer: This explanation mentions: Buenos d\u00edas, \u00bfC\u00f3mo est\u00e1s?.", "metrics": {"clarity": {"value": 5, "confidence": 0.96, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.71, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.77, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.94, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.8, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.78, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.84, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_009"}}}
{"case_id": "test_010", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=16, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.457481Z", "trace_id": "151a3736-d0bc-4036-86ef-bf52712e7b49", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain the concept of supply and demand.\n\nAnswer: This explanation mentions: price signals, equilibrium, market forces.", "metrics": {"clarity": {"value": 5, "confidence": 0.75, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.62, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.7, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.61, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.6, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.65, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.63, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_010"}}}
{"case_id": "test_011", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.467252Z", "trace_id": "21c2a414-56c8-4638-9a36-568324bb2f59", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is the main idea of a paragraph that starts with 'In 1914...'?\n\nAnswer: This explanation mentions: WWI context, timeline, causes.", "metrics": {"clarity": {"value": 3, "confidence": 0.73, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.81, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.64, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.66, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.77, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.96, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.72, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_011"}}}
{"case_id": "test_012", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=21, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6624999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.477423Z", "trace_id": "5bef4da3-04ce-4737-8eaf-8c3a7d543d7f", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain photosynthesis to a 5th grader using a short metaphor.\n\nAnswer: This explanation mentions: sun energy, food for plant, simple metaphor.", "metrics": {"clarity": {"value": 5, "confidence": 0.74, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.75, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.87, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.93, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.98, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.75, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.91, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_012"}}}
{"case_id": "test_013", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=26, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.477423Z", "trace_id": "6d4e1b34-15fd-4d38-837c-df53fe64c881", "query_type": "other", "failed": false, "raw": {"tutor_response": "A student asks: 'How do I factor x^2 - 5x + 6?' Provide steps and checks.\n\nAnswer: This explanation mentions: find roots, (x-2)(x-3), check by expansion.", "metrics": {"clarity": {"value": 5, "confidence": 0.74, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.63, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.61, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.78, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.85, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.94, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.8, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_013"}}}
{"case_id": "test_014", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 4, "confidence": 0.8, "notes": "Code present; not deeply analyzed"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.490391Z", "trace_id": "bf2ff373-b59d-42c3-a832-e80ee8b64109", "query_type": "other", "failed": false, "raw": {"tutor_response": "Assess this short code: def add(a,b): return a+b \u2014 what tests would you write?\n\nAnswer: This explanation mentions: unit tests, edge cases, type checks.", "metrics": {"clarity": {"value": 4, "confidence": 0.79, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.7, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.98, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.83, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.62, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.83, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.61, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_014"}}}
{"case_id": "test_015", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:32:23.497214Z", "trace_id": "6567f2a4-0de0-4ba9-8cab-c9ea19632a94", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the greenhouse effect in three simple points for grade 8.\n\nAnswer: This explanation mentions: energy trapping, greenhouse gases, temperature rise.", "metrics": {"clarity": {"value": 3, "confidence": 0.66, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.94, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.81, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.82, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.63, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.98, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.97, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_015"}}}
{"case_id": "test_001", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.857336Z", "trace_id": "f0ad5727-b89b-418a-82c5-f86f7fd39d91", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is photosynthesis?\n\nAnswer: This explanation mentions: sunlight, chlorophyll, glucose.", "metrics": {"clarity": {"value": 3, "confidence": 0.87, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.81, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.7, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 1.0, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.95, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.78, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.9, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_001"}}}
{"case_id": "test_002", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.857336Z", "trace_id": "809de454-4f10-4f88-9499-a381b8a64022", "query_type": "problem_solving", "failed": false, "raw": {"tutor_response": "Solve 2x + 5 = 15. Show steps.\n\nAnswer: This explanation mentions: isolate variable, subtract 5, divide by 2.", "metrics": {"clarity": {"value": 3, "confidence": 0.84, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.9, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.91, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.94, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.7, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.88, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.83, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_002"}}}
{"case_id": "test_003", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.88, "notes": "3/5 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/5 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=10, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6499999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.879584Z", "trace_id": "a8314801-08b9-4864-b968-0ea1fb56695d", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain mitosis briefly.\n\nAnswer: This explanation mentions: prophase, metaphase, anaphase.", "metrics": {"clarity": {"value": 3, "confidence": 0.64, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.93, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.7, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.91, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.68, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.86, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.91, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_003"}}}
{"case_id": "test_004", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=15, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.881588Z", "trace_id": "00bfcb36-4b28-4f7d-b72d-bcfe883bc96a", "query_type": "other", "failed": false, "raw": {"tutor_response": "What caused the American Civil War?\n\nAnswer: This explanation mentions: slavery, states' rights, economic differences.", "metrics": {"clarity": {"value": 5, "confidence": 0.72, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.72, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.89, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.81, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.84, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.92, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.9, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_004"}}}
{"case_id": "test_005", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=19, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.893234Z", "trace_id": "30e7043b-8c2d-467b-b55d-d9d13cf3a186", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the plot of 'Romeo and Juliet' in 3 sentences.\n\nAnswer: This explanation mentions: feuding families, young love, tragedy.", "metrics": {"clarity": {"value": 3, "confidence": 0.93, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.73, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.95, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.81, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.98, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.81, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.87, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_005"}}}
{"case_id": "test_006", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=17, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.899396Z", "trace_id": "0aca229a-cfe0-4c27-95fb-9942c0108417", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain why water expands when it freezes.\n\nAnswer: This explanation mentions: hydrogen bonds, lattice structure, lower density.", "metrics": {"clarity": {"value": 4, "confidence": 0.96, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.97, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.65, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.88, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.65, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.77, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.71, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_006"}}}
{"case_id": "test_007", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=13, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.907188Z", "trace_id": "7f33af1e-6de0-4c9e-a659-a415f79119f8", "query_type": "other", "failed": false, "raw": {"tutor_response": "Find derivative of f(x)=3x^2+2x.\n\nAnswer: This explanation mentions: power rule, 2*3x, result 6x+2.", "metrics": {"clarity": {"value": 5, "confidence": 0.61, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.65, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.91, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.79, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.71, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.95, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.63, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_007"}}}
{"case_id": "test_008", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.625, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.908701Z", "trace_id": "c395393d-256c-4fda-8fda-9b18b3ff0bba", "query_type": "other", "failed": false, "raw": {"tutor_response": "Give a step-by-step plan to debug a Python function that raises a TypeError.\n\nAnswer: This explanation mentions: inspect stack trace, check types, add asserts.", "metrics": {"clarity": {"value": 5, "confidence": 0.64, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.61, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.9, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.68, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.62, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.69, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.71, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_008"}}}
{"case_id": "test_009", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "2 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "2/2 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "2/2 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=19, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.5625, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.908701Z", "trace_id": "0480b167-e33c-40e4-82d0-aa29c5d82919", "query_type": "other", "failed": false, "raw": {"tutor_response": "Translate 'Good morning' to Spanish and provide a polite follow-up question.\n\nAnswer: This explanation mentions: Buenos d\u00edas, \u00bfC\u00f3mo est\u00e1s?.", "metrics": {"clarity": {"value": 3, "confidence": 1.0, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.98, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.83, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.92, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.88, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.88, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.9, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_009"}}}
{"case_id": "test_010", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=16, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.925066Z", "trace_id": "afb5f3ff-218c-4c33-8e3a-c3ee9840b70d", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain the concept of supply and demand.\n\nAnswer: This explanation mentions: price signals, equilibrium, market forces.", "metrics": {"clarity": {"value": 3, "confidence": 0.73, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.6, "notes": "Mocked score for completeness"}, "accuracy": {"value": 4, "confidence": 0.73, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.91, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 4, "confidence": 0.64, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.92, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.66, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_010"}}}
{"case_id": "test_011", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=high_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.59375, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.925066Z", "trace_id": "2f6c0433-2285-45b2-bb1a-2895e39ea6fb", "query_type": "other", "failed": false, "raw": {"tutor_response": "What is the main idea of a paragraph that starts with 'In 1914...'?\n\nAnswer: This explanation mentions: WWI context, timeline, causes.", "metrics": {"clarity": {"value": 5, "confidence": 0.71, "notes": "Mocked score for clarity"}, "completeness": {"value": 5, "confidence": 0.76, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.86, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 5, "confidence": 0.9, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.64, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 3, "confidence": 0.64, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 4, "confidence": 0.73, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_011"}}}
{"case_id": "test_012", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 3, "confidence": 0.7, "notes": "word_count=21, grade=elementary"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6624999999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.940825Z", "trace_id": "c85f2d63-83b5-48bc-b3f9-ff185ec931c1", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Explain photosynthesis to a 5th grader using a short metaphor.\n\nAnswer: This explanation mentions: sun energy, food for plant, simple metaphor.", "metrics": {"clarity": {"value": 4, "confidence": 0.9, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.79, "notes": "Mocked score for completeness"}, "accuracy": {"value": 5, "confidence": 0.9, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 3, "confidence": 0.86, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.75, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 4, "confidence": 0.67, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.7, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_012"}}}
{"case_id": "test_013", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=26, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.948864Z", "trace_id": "294b52b7-c05e-4a82-baab-8a95b119e0e1", "query_type": "other", "failed": false, "raw": {"tutor_response": "A student asks: 'How do I factor x^2 - 5x + 6?' Provide steps and checks.\n\nAnswer: This explanation mentions: find roots, (x-2)(x-3), check by expansion.", "metrics": {"clarity": {"value": 5, "confidence": 0.89, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.89, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.81, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.68, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 0.8, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.66, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.85, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_013"}}}
{"case_id": "test_014", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 4, "confidence": 0.92, "notes": "3/4 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/4 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=24, grade=college"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 4, "confidence": 0.8, "notes": "Code present; not deeply analyzed"}, "pedagogy_alignment": {"value": 4, "confidence": 0.6, "notes": "some scaffolding indicators found: 1"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.65625, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.956348Z", "trace_id": "101db8e6-3501-4f87-9e13-33c54e5c8351", "query_type": "other", "failed": false, "raw": {"tutor_response": "Assess this short code: def add(a,b): return a+b \u2014 what tests would you write?\n\nAnswer: This explanation mentions: unit tests, edge cases, type checks.", "metrics": {"clarity": {"value": 3, "confidence": 0.86, "notes": "Mocked score for clarity"}, "completeness": {"value": 3, "confidence": 0.93, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.82, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.6, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 3, "confidence": 1.0, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.67, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 5, "confidence": 0.84, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_014"}}}
{"case_id": "test_015", "job_id": "local-sync", "engine_id": "mock/0.1", "scores": {"clarity": {"value": 4, "confidence": 0.8, "notes": "3 expected concepts found"}, "completeness": {"value": 5, "confidence": 1.0, "notes": "3/3 expected concepts present"}, "accuracy": {"value": 4, "confidence": 0.6, "notes": "3/3 expected concepts matched"}, "appropriateness": {"value": 4, "confidence": 0.7, "notes": "word_count=21, grade=middle_school"}, "long_term_memory": {"value": 3, "confidence": 0.4, "notes": "no prior context in case"}, "code_quality": {"value": 3, "confidence": 0.5, "notes": "Not applicable / no code"}, "pedagogy_alignment": {"value": 2, "confidence": 0.4, "notes": "no scaffolding indicators found"}, "multimodal_appropriateness": {"value": 2, "confidence": 0.6, "notes": "no suggested media"}}, "aggregated_score": 0.6937499999999999, "status": "evaluated", "evaluated_at": "2025-11-13T17:33:04.963498Z", "trace_id": "119897fd-3fc7-4384-942b-56dc6e6276b7", "query_type": "explanation", "failed": false, "raw": {"tutor_response": "Summarize the greenhouse effect in three simple points for grade 8.\n\nAnswer: This explanation mentions: energy trapping, greenhouse gases, temperature rise.", "metrics": {"clarity": {"value": 3, "confidence": 0.94, "notes": "Mocked score for clarity"}, "completeness": {"value": 4, "confidence": 0.93, "notes": "Mocked score for completeness"}, "accuracy": {"value": 3, "confidence": 0.98, "notes": "Mocked score for accuracy"}, "appropriateness": {"value": 4, "confidence": 0.78, "notes": "Mocked score for appropriateness"}, "long_term_memory": {"value": 5, "confidence": 0.95, "notes": "Mocked score for long_term_memory"}, "code_quality": {"value": 5, "confidence": 0.8, "notes": "Mocked score for code_quality"}, "pedagogy_alignment": {"value": 3, "confidence": 0.72, "notes": "Mocked score for pedagogy_alignment"}}, "meta": {"seed": 42, "case_id": "test_015"}}}
